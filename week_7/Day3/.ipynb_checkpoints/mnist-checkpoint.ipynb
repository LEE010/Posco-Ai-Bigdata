{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SOURCE_URL = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "FILENAME = SOURCE_URL.split('/')[-1]\n",
    "DATA_DIR = './datasets'\n",
    "\n",
    "def maybe_download(data_dir):\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    if not os.path.isfile(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading {} {:.1f} %'.format(\n",
    "                FILENAME, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully donloaded', FILENAME, statinfo.st_size, 'bytes.')\n",
    "\n",
    "def load(data_dir, subset='train'):\n",
    "    maybe_download(data_dir)\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    \n",
    "    f = gzip.open(filepath, 'rb')\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    train_set, valid_set, test_set = u.load()\n",
    "    f.close()\n",
    "    \n",
    "    if subset == 'train':\n",
    "        trainx, trainy = train_set\n",
    "        trainx = trainx.astype(np.float32).reshape(trainx.shape[0], 28, 28)\n",
    "        trainy = trainy.astype(np.uint8)\n",
    "        return trainx, trainy\n",
    "    elif subset == 'test':\n",
    "        testx, testy = test_set\n",
    "        testx = testx.astype(np.float32).reshape(testx.shape[0], 28, 28)\n",
    "        testy = testy.astype(np.uint8)\n",
    "        return testx, testy\n",
    "    elif subset== 'valid':\n",
    "        validx, validy = valid_set\n",
    "        validx = validx.astype(np.float32).reshape(validx.shape[0], 28, 28)\n",
    "        validy = validy.astype(np.uint8)\n",
    "        return validx, validy\n",
    "    else:\n",
    "        raise NotImplementedError('subset should be train or valid or test')\n",
    "\n",
    "# Load data\n",
    "train_data, train_label = load(DATA_DIR, 'train')\n",
    "valid_data, valid_label = load(DATA_DIR, 'valid')\n",
    "test_data, test_label = load(DATA_DIR, 'test')\n",
    "\n",
    "# concatenate train and valid data as train data\n",
    "train_data = np.concatenate((train_data, valid_data))\n",
    "train_label = np.concatenate((train_label, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 확인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[4]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "batch_size = 100 # 한 에폭마다 셔플 후 128개를(2^n)개 샘플링 해야 정석!\n",
    "num_display = 100\n",
    "\n",
    "def get_model(X,by):\n",
    "    X = tf.expand_dims(X, axis=3) #3차원으로 늘린다 (None,28,28) \n",
    "    \n",
    "    with tf.variable_scope('first',reuse=tf.AUTO_REUSE):\n",
    "        outs = tf.layers.conv2d(X, 128, 3, padding='same') # 일반적인 CNN은 크기를 줄이지 않기 때문에 패딩을 넣는다.\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs,2,2)\n",
    "        \n",
    "    with tf.variable_scope('second',reuse=tf.AUTO_REUSE):\n",
    "        outs = tf.layers.conv2d(outs, 256, 3, padding='same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs,2,2)\n",
    "        \n",
    "    with tf.variable_scope('third',reuse=tf.AUTO_REUSE):\n",
    "        outs = tf.layers.conv2d(outs, 64, 3, padding='same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs,2,2)\n",
    "    \n",
    "    outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "    outs = tf.layers.dense(outs, 128)\n",
    "    outs = tf.nn.relu(outs)\n",
    "    outs = tf.layers.dense(outs, 10)\n",
    "    \n",
    "    one_hot = tf.one_hot(by, 10)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outs,labels=one_hot)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    preds = tf.cast(tf.math.arg_max(tf.nn.softmax(outs),axis = 1), tf.int32)\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(by,preds), tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return {'loss':loss, 'opt':opt, 'preds':preds, \"acc\":acc, 'init': init}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable first/conv2d/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c8b1b2a71e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ff7a8addd278>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(X, by)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 일반적인 CNN은 크기를 줄이지 않기 때문에 패딩을 넣는다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       _scope=name)\n\u001b[0;32m--> 417\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_learning_phase_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m           \u001b[0;31m# the user has manually overwritten the build method do we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0;31m# build it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    637\u001b[0m     new_variable = getter(\n\u001b[1;32m    638\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    877\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    878\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;31m# Create the tensor to initialize the variable with default value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable first/conv2d/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None,28,28))\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n",
    "model = get_model(X,by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a859c9ac12e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current iteration {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_epoch\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(model['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch +1))\n",
    "        \n",
    "        for ind_ in range(0, int(60000 / batch_size)):\n",
    "            batch_X = train_data[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = train_label[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            \n",
    "            _, cur_loss, cur_acc = sess.run([model['opt'], model['loss'], model['acc']],\n",
    "                                            feed_dict={X:batch_X, by: batch_by})\n",
    "            \n",
    "            if ind_ % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    \n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    \n",
    "    for ind_ in range(0,10):\n",
    "        cur_loss, cur_acc = sess.run([model['loss'], model['acc']],\n",
    "                                      feed_dict={X:test_data, by: test_label})\n",
    "            \n",
    "        print('Test: loss {0:.4f} Test: acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

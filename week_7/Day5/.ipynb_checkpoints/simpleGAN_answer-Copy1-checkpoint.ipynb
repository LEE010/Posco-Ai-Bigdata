{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:3])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img\n",
    "\n",
    "\n",
    "def plot_network_output(data, reconst_data, generated, step):\n",
    "    num = 8\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=num, figsize=(18, 6))\n",
    "    for i in xrange(num):\n",
    "        ax[(0, i)].imshow(np.squeeze(generated[i]), cmap=plt.cm.gray)\n",
    "        ax[(1, i)].imshow(np.squeeze(data[i]), cmap=plt.cm.gray)\n",
    "        ax[(2, i)].imshow(np.squeeze(reconst_data[i]), cmap=plt.cm.gray)\n",
    "        ax[(0, i)].axis('off')\n",
    "        ax[(1, i)].axis('off')\n",
    "        ax[(2, i)].axis('off')\n",
    "\n",
    "    fig.suptitle('Top: generated | Middle: data | Bottom: recunstructed')\n",
    "#     plt.show()\n",
    "    plt.savefig(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2db0b5470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "# ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax1.imshow(np.array(sample_data*255, dtype=np.uint8), 'gray')\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "#         shp = inputs.get_shape().as_list()[-1]\n",
    "        \n",
    "        weight = tf.get_variable('w',shape=[inputs.shape[1],out_channel],\n",
    "                                initializer=tf.initializers.glorot_normal())\n",
    "\n",
    "        bias = tf.get_variable('b', shape=[batch_size,out_channel],\n",
    "                              initializer=tf.initializers.zeros)\n",
    "\n",
    "        fc = tf.matmul(inputs, weight)+bias\n",
    "\n",
    "        return fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=None):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 28, 28, 1]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # Vectorize the input x\n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 1 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Return the final tensor\n",
    "        net = tf.reshape(x, (-1, x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        net = fully_connected(net,256,'fc1')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = fully_connected(net,1,'fc2')\n",
    "        net = tf.nn.sigmoid(net)\n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        # Unlike the discriminator, input z is a set of vectors\n",
    "        \n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 784 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Reshape final output to be a proper image file [28, 28, 1]\n",
    "        # Return the final tensor\n",
    "        net = fully_connected(z,256,'fc1')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = fully_connected(net,784,'fc2')\n",
    "        net = tf.nn.sigmoid(net)\n",
    "        net = tf.reshape(net,(-1,28,28,1))\n",
    "                         \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_rake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = -tf.reduce_mean(tf.log(D_real+eps) + tf.log(1-D_fake +eps))\n",
    "    G_loss = -tf.reduce_mean(tf.log(D_fake +eps))\n",
    "\n",
    "    return D_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "\n",
    "train_data = np.expand_dims(train_data, 3)\n",
    "test_data = np.expand_dims(test_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28, 28, 1], name='input_x')\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = tf.random_uniform((batch_size, z_dim), -1., 1., name='latent_z')\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "D_real = discriminator(x, reuse=False)\n",
    "# Build generator\n",
    "G = generator(z)\n",
    "# Build discriminator where input data is generated image G\n",
    "D_fake = discriminator(G, reuse=True)\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "D_loss, G_loss = get_loss(D_real, D_fake)\n",
    "\n",
    "# Make optimization op\n",
    "opt = tf.train.AdamOptimizer(lr, beta1=beta1)\n",
    "\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "G_params = [param for param in tf.trainable_variables()\n",
    "            if 'generator' in param.name]\n",
    "D_params = [param for param in tf.trainable_variables()\n",
    "            if 'discriminator' in param.name]\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = opt.minimize(D_loss, var_list=D_params)\n",
    "G_train = opt.minimize(G_loss, var_list=G_params)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add summary and make op to add summary data to event log\n",
    "tf.summary.scalar('Generator_loss', G_loss)\n",
    "tf.summary.scalar('Discriminator_loss', D_loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-3a06a5c21535>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-3a06a5c21535>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fully_connectedwith tf.Session() as sess:\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    writer = tf.summary.FileWriter(\"./board/xor_logs_ro_01\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.close()\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled, cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled, cmap=plt.cm.gray)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled, cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled, cmap=plt.cm.gray)\n",
    "#             plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# Make gif files\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

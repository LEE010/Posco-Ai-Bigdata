{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = unpickle(\"/home/pirl/cifar-100-python/test\")\n",
    "train = unpickle(\"/home/pirl/cifar-100-python/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[b'data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.transpose(train[b'data'].reshape(-1,3,32,32),(0,2,3,1))\n",
    "train_y = train[b'fine_labels']\n",
    "test_x = np.transpose(test[b'data'].reshape(-1,3,32,32),(0,2,3,1))\n",
    "test_y = test[b'fine_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "num_display = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screensh](https://cdn-images-1.medium.com/max/1600/1*M5NIelQC33eN6KjwZRccoQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X,filters,name,strides=(1,1)):\n",
    "    outs = tf.layers.conv2d(X, filters, 3,strides=strides, padding='same', name=name, reuse=tf.AUTO_REUSE)\n",
    "    outs = bn(outs,name)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(X,name):\n",
    "    with tf.variable_scope(name):\n",
    "        batch_mean, batch_var = tf.nn.moments(X,[0])\n",
    "    return tf.nn.batch_normalization(X,batch_mean,batch_var,0,1,1e-3,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X,filters,name):\n",
    "    with tf.variable_scope(name):\n",
    "        outs = conv(X,filters,name)\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = conv(outs,filters,name)\n",
    "        outs = tf.nn.relu(X + outs)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X,filters,name):\n",
    "    with tf.variable_scope(name):\n",
    "        outs = tf.layers.conv2d(X, filters, 3,(2,2),padding='same', name=name, reuse=tf.AUTO_REUSE)\n",
    "#         outs = tf.layers.conv2d(outs, filters*2,3,padding='same', name=name, reuse=tf.AUTO_REUSE)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def skip_connection(X,filters,name):\n",
    "#     with tf.variable_scope(name):\n",
    "#         sc = conv(X,filters,name,strides=(2,2))\n",
    "#         sc = conv(sc,filters,name)\n",
    "#     return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(X,by):\n",
    "    outs = tf.layers.conv2d(X,64,1,padding='same',name='conv-1', reuse=False)\n",
    "#     outs = tf.layers.max_pooling2d(outs,2,(2,2))\n",
    "#     print(outs.shape)\n",
    "    outs = convolutional_block(outs,64,'conv-block-1')\n",
    "    outs = identity_block(outs,128,'identity-1')\n",
    "    outs = convolutional_block(outs,128,'conv-block-2')\n",
    "    outs = identity_block(outs,256,'identity-2')\n",
    "    outs = convolutional_block(outs,256,'conv-block-3')\n",
    "    outs = identity_block(outs,512,'identity-3')\n",
    "    outs = convolutional_block(outs,512,'conv-block-4')\n",
    "    outs = tf.layers.average_pooling2d(outs,2,(2,2))\n",
    "    \n",
    "    outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "    outs = tf.layers.dense(outs, 100, name='dense')\n",
    "    \n",
    "    one_hot = tf.one_hot(by, 100)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outs, \n",
    "                                                      labels=one_hot)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "    preds = tf.cast(tf.argmax(tf.nn.softmax(outs), axis=1), tf.int32)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(by, preds), tf.float32))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    return {\n",
    "        'init': init,\n",
    "        'loss': loss,\n",
    "        'opt': opt,\n",
    "        'preds': preds,\n",
    "        'acc': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "by = tf.placeholder(tf.int32)\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "\n",
    "model = ResNet(X, by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 13.0016 acc 0.0300\n",
      "loss 4.1016 acc 0.0700\n",
      "loss 3.6174 acc 0.1300\n",
      "loss 3.7340 acc 0.1800\n",
      "loss 3.2829 acc 0.2000\n",
      "Test: loss 3.1005 Test: acc 0.2480\n",
      "Current iteration 2\n",
      "loss 3.1720 acc 0.2800\n",
      "loss 3.0143 acc 0.2600\n",
      "loss 2.6539 acc 0.3500\n",
      "loss 2.9920 acc 0.3100\n",
      "loss 2.7088 acc 0.2600\n",
      "Test: loss 2.7247 Test: acc 0.3176\n",
      "Current iteration 3\n",
      "loss 2.5891 acc 0.3400\n",
      "loss 2.4679 acc 0.3200\n",
      "loss 2.1997 acc 0.4200\n",
      "loss 2.4167 acc 0.3900\n",
      "loss 2.1965 acc 0.3700\n",
      "Test: loss 2.6286 Test: acc 0.3430\n",
      "Current iteration 4\n",
      "loss 2.1286 acc 0.4300\n",
      "loss 2.0061 acc 0.4800\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(model['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "        \n",
    "        for ind_ in range(0, int(50000 / batch_size)):\n",
    "            batch_X = train_x[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = np.array(train_y[ind_*batch_size:(ind_+1)*batch_size])\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [model['opt'], model['loss'], model['acc']],\n",
    "                feed_dict={X: batch_X, by: batch_by})\n",
    "            if ind_ % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    \n",
    "        cur_acc_all = 0.0\n",
    "        cur_loss_all = 0.0\n",
    "\n",
    "        for ind_ in range(0,10):\n",
    "            cur_loss, cur_acc = sess.run([model['loss'], model['acc']],\n",
    "                                          feed_dict={X:test_x[ind_*1000:(ind_+1)*1000], by: test_y[ind_*1000:(ind_+1)*1000]})\n",
    "            cur_loss_all += cur_loss\n",
    "            cur_acc_all += cur_acc\n",
    "        print('Test: loss {0:.4f} Test: acc {1:.4f}'.format(cur_loss_all/10, cur_acc_all/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
